name: CI/CD (Lint, Tests, Train, Build & Push)

on:
  push:
    branches: ["main"]
  pull_request:
  workflow_dispatch:

env:
  # image docker hub: <username>/<repo>
  DOCKER_IMAGE: ${{ secrets.DOCKERHUB_USERNAME }}/student-success-api

jobs:
  lint_test:
    name: Lint + Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r fastapi_app/requirements.txt
          pip install -r requirements-dev.txt
          pip install ruff pytest pytest-asyncio

      - name: Ruff (lint)
        run: ruff check fastapi_app

      - name: Pytest
        run: pytest -q fastapi_app/tests

  train_model:
    name: Train model (produces joblib)
    runs-on: ubuntu-latest
    needs: [lint_test]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r fastapi_app/requirements.txt

      - name: Train -> fastapi_app/models/best_model_rf_seed.joblib
        env:
          DATA_PATH: data/final.csv
        run: |
          python - <<'PY'
          import os
          import json
          import numpy as np
          import pandas as pd
          import joblib
          from pathlib import Path

          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
          from sklearn.ensemble import RandomForestRegressor
          from sklearn.model_selection import train_test_split
          from sklearn.metrics import mean_absolute_error, r2_score
          from transforms import safe_log1p_absences


          data_path = os.getenv("DATA_PATH", "data/final.csv")
          if not Path(data_path).exists():
              raise FileNotFoundError(f"Dataset introuvable: {data_path}")

          df = pd.read_csv(data_path)

          target = "G3"
          if target not in df.columns:
              raise ValueError("Colonne cible 'G3' absente du dataset.")

          X = df.drop(columns=[target])
          y = df[target].astype(float)

          # Colonnes catégorielles vs numériques (cohérent API)
          cat_cols = X.select_dtypes(exclude=["number"]).columns.tolist()
          num_cols = X.select_dtypes(include=["number"]).columns.tolist()

          # -------- Option A : log1p UNIQUEMENT sur absences --------
          ABS_COL = "absences"
          num_cols_no_abs = [c for c in num_cols if c != ABS_COL]


          abs_pipe = Pipeline(steps=[
              ("log1p", FunctionTransformer(safe_log1p_absences, feature_names_out="one-to-one")),
              ("scaler", StandardScaler()),
          ])

          num_pipe = Pipeline(steps=[
              ("scaler", StandardScaler()),
          ])

          pre = ColumnTransformer(
              transformers=[
                  ("num", num_pipe, num_cols_no_abs),
                  ("absences", abs_pipe, [ABS_COL]) if ABS_COL in X.columns else ("num_abs_fallback", num_pipe, []),
                  ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
              ],
              remainder="drop",
          )
          # ----------------------------------------------------------

          # Modèle seed (simple, déterministe)
          model = RandomForestRegressor(
              random_state=42,
              n_estimators=700,
              n_jobs=-1
          )

          pipe = Pipeline([("preprocess", pre), ("model", model)])

          X_train, X_test, y_train, y_test = train_test_split(
              X, y, test_size=0.2, random_state=42
          )
          pipe.fit(X_train, y_train)

          y_pred = pipe.predict(X_test)
          mae = float(mean_absolute_error(y_test, y_pred))
          r2 = float(r2_score(y_test, y_pred))

          out_dir = Path("fastapi_app/models")
          out_dir.mkdir(parents=True, exist_ok=True)

          model_path = out_dir / "best_model_rf.joblib"
          joblib.dump(pipe, model_path, compress=3)

          metrics_path = out_dir / "metrics.json"
          metrics_path.write_text(json.dumps({"mae": mae, "r2": r2}, indent=2))

          print("Saved model:", model_path)
          print("Saved metrics:", metrics_path, {"mae": mae, "r2": r2})
          PY

      - name: Upload model artifact
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts
          path: |
            fastapi_app/models/best_model_rf.joblib
            fastapi_app/models/metrics.json

  build_push:
    name: Build & Push Docker image (API)
    runs-on: ubuntu-latest
    needs: [train_model]
    # On pousse sur Docker Hub uniquement sur push main, pas sur PR
    if: github.event_name == 'push'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: fastapi_app/models

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build & Push
        uses: docker/build-push-action@v6
        with:
          context: fastapi_app
          file: fastapi_app/Dockerfile
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE }}:latest
            ${{ env.DOCKER_IMAGE }}:${{ github.sha }}
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.revision=${{ github.sha }}
